{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HComr76TT-QJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab code to unzip the database:"
      ],
      "metadata": {
        "id": "1wSwDnJPUP4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####    GIVEN CODE    ####\n",
        "import zipfile\n",
        "!rm /content/download\n",
        "!rm -r /content/imagedb/\n",
        "!rm -r /content/imagedb_test\n",
        "!wget https://vc.ee.duth.gr:6960/index.php/s/wlnkxtlGmqBeATC/download\n",
        "local_zip = '/content/download'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "qUpDeW1qUN5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declaring training and testing directories \n",
        "train_dir = '/content/imagedb'                # train_folders\n",
        "test_dir  = '/content/imagedb_test'           # testing_folders"
      ],
      "metadata": {
        "id": "gVBamBCsUT00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = 32 \n",
        "epochs = 600     \n",
        "do = 0.5  # drop out rate\n",
        "bs = 20   # batch_size\n",
        "ks = 3    # kernel size\n",
        "\n",
        "image_dimension = 256"
      ],
      "metadata": {
        "id": "SU-_iDrKaT4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Auto find the nodes of the last layer ##\n",
        "classes = []\n",
        "for dirname, _, filenames in os.walk('/content/imagedb_test'):\n",
        "  # print(dirname)\n",
        "  a,folder = dirname.split(\"/content/imagedb_test\")\n",
        "  folder = folder[1:]\n",
        "  # print(folder)\n",
        "  classes.append(folder)\n",
        "\n",
        "classes = classes[1:]\n",
        "print(classes)\n",
        "\n",
        "out_nodes = len(classes)\n",
        "print(\"\\nThe nodes of the last layer and the number of classes is: \" + str(out_nodes))"
      ],
      "metadata": {
        "id": "9DY-p6UnqRp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers"
      ],
      "metadata": {
        "id": "LS0nIZgUpkjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "# Load the pre-trained model\n",
        "pre_trained = ResNet50(include_top=False, #whether we are including a fully connected layer or not\n",
        "                       weights='imagenet',\n",
        "                       input_shape=(224, 224, 3))\n",
        "# pre_trained.summary()"
      ],
      "metadata": {
        "id": "A4CIQdC2JzzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Keeping active the first 100 layers\n",
        "# for layer in pre_trained.layers[:]:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Check the trainable status of the individual layers\n",
        "# for layer in pre_trained.layers:\n",
        "#     print(layer, layer.trainable)"
      ],
      "metadata": {
        "id": "NbHwH8JTDyyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting the pre-trained model with my model\n",
        "model = models.Sequential()\n",
        "model.add(pre_trained)\n",
        "\n",
        "    # nodes = 32\n",
        "model.add(layers.Conv2D(filters=nodes*4, kernel_size=(ks,ks), activation='relu'))\n",
        "model.add(layers.Conv2D(filters=nodes*4, kernel_size=(ks,ks), activation='relu'))\n",
        "model.add(layers.Conv2D(filters=nodes*4, kernel_size=(ks,ks), activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(3,3), padding='same'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512,activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(rate=do))\n",
        "\n",
        "model.add(layers.Dense(out_nodes,activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "vGsjTW_MUcl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import ResNet50\n",
        "# DATA AGMENTATION \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_gen = ImageDataGenerator(rescale = 1./255, \n",
        "                                    rotation_range = 10,\n",
        "                                    brightness_range = [0.5 , 1],\n",
        "                                    zoom_range = [0.15 , 1],\n",
        "                                    validation_split = 0.2,\n",
        "                                    horizontal_flip=False,\n",
        "                                    vertical_flip=False,\n",
        "                                    fill_mode=\"nearest\")\n",
        "\n",
        "# --------------------\n",
        "# Flow training images in batches of bs using train_data_gen generator\n",
        "# --------------------\n",
        "train_generator = train_data_gen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=bs,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    # color_mode='grayscale',\n",
        "                                                    target_size=(image_dimension, image_dimension),\n",
        "                                                    shuffle=True,\n",
        "                                                    subset='training', seed=1)     \n",
        "# --------------------\n",
        "# Flow validation images in batches of bs using train_data_gen generator\n",
        "# --------------------\n",
        "validation_generator = train_data_gen.flow_from_directory(train_dir,\n",
        "                                                      batch_size=100,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      # color_mode='grayscale',\n",
        "                                                      target_size=(image_dimension, image_dimension),\n",
        "                                                      subset='validation', seed=1) "
      ],
      "metadata": {
        "id": "IG_hOdNrVjAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Train the model -----\n",
        "\n",
        "callbacks = []\n",
        "\n",
        "save_best_callback = tf.keras.callbacks.ModelCheckpoint(f'hw4.hdf5', save_best_only=True, verbose=1)\n",
        "callbacks.append(save_best_callback)\n",
        "\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                                       min_delta=0, \n",
        "                                                       patience=5, \n",
        "                                                       verbose=1, \n",
        "                                                       mode='auto', \n",
        "                                                       restore_best_weights=True)\n",
        "callbacks.append(early_stop_callback)\n",
        "\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=1,\n",
        "      shuffle=True,\n",
        "      callbacks=callbacks)"
      ],
      "metadata": {
        "id": "-lOP1rc7VlhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------\n",
        "# Flow validation images in batches of 20 using datagen generator\n",
        "# --------------------\n",
        "test_data_gen = ImageDataGenerator( rescale = 1./255, \n",
        "                                    brightness_range = [0.5 , 1],\n",
        "                                    zoom_range = [0.15 , 1],\n",
        "                                    horizontal_flip=False,\n",
        "                                    vertical_flip=False\n",
        "                                   )\n",
        "\n",
        "test_generator = test_data_gen.flow_from_directory(test_dir,\n",
        "                                                   batch_size=100,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   # color_mode='grayscale',\n",
        "                                                   shuffle=False,\n",
        "                                                   target_size=(image_dimension, image_dimension)) \n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "6F2UC0swax1f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}